# üî¨ C√¥ng Th·ª©c Fuzzy Entropy De Luca - Quick Reference

## üìê C√¥ng Th·ª©c Ch√≠nh

### Fuzzy Entropy De Luca (Shannon)
$$H = -K \sum_{i=1}^{n} \left[ \rho_i \log(\rho_i) + (1-\rho_i) \log(1-\rho_i) \right]$$

| K√Ω hi·ªáu | Gi√° tr·ªã | √ù nghƒ©a |
|---------|--------|--------|
| H | > 0 | ƒê·ªô m·ªù (entropy) c·ªßa ph√¢n ƒëo·∫°n |
| K | 1/ln(2) ‚âà 1.4427 | H·∫±ng s·ªë chu·∫©n ho√° |
| n | 256 | S·ªë m·ª©c x√°m (8-bit) |
| œÅ_i | [0, 1] | ƒê·ªô th√†nh vi√™n m·ªù c·ªßa pixel i |

### Shannon Entropy Component
$$S_n(\rho) = -\rho \log(\rho) - (1-\rho) \log(1-\rho)$$

| œÅ | S_n(œÅ) | √ù nghƒ©a |
|---|--------|--------|
| 0 | 0 | Ho√†n to√†n kh√¥ng thu·ªôc l·ªõp |
| 0.5 | 0.693 (max) | M·ªù t·ªëi ƒëa, kh√¥ng ch·∫Øc ch·∫Øn |
| 1 | 0 | Ho√†n to√†n thu·ªôc l·ªõp |

---

## üéØ C√¥ng Th·ª©c Ph·∫°t (Penalty)

### T·ªïng Qu√°t
$$F'(T) = F(T) - \lambda[\alpha P_A(T) + \beta P_\mu(T)]$$

| K√Ω hi·ªáu | Gi√° tr·ªã | √ù nghƒ©a |
|---------|--------|--------|
| F(T) | - | Fuzzy Entropy g·ªëc |
| Œª | 1.0 | H·ªá s·ªë c√¢n n·∫∑ng chung |
| Œ± | 0.1 | H·ªá s·ªë penalty di·ªán t√≠ch |
| Œ≤ | 0.1 | H·ªá s·ªë penalty membership |
| P_A(T) | ‚â• 0 | Penalty di·ªán t√≠ch |
| P_Œº(T) | ‚â• 0 | Penalty membership |

### Penalty Di·ªán T√≠ch
$$P_A(T) = \sum_{c=1}^{C} \left( p_c - \frac{1}{C} \right)^2$$

**√ù nghƒ©a:** Ph·∫°t n·∫øu c√°c l·ªõp kh√¥ng c√¢n b·∫±ng

### Penalty Membership  
$$P_\mu(T) = \max_{c,y}(\mu_c(y))^2$$

**√ù nghƒ©a:** Ph·∫°t n·∫øu membership qu√° t·∫≠p trung

---

## üßÆ T√≠nh To√°n Tr√™n Histogram

### Ph√¢n Ph·ªëi X√°c Su·∫•t
$$p(y) = \frac{hist[y]}{\sum_{y=0}^{255} hist[y]}$$

### ƒê·ªô Th√†nh Vi√™n M·ªói L·ªõp
$$p_c = \sum_{y=0}^{255} \mu_c(y) \cdot p(y)$$

### Fuzzy Entropy T·ªïng Th·ªÉ
$$H = C \cdot \frac{1}{\ln(2)} \sum_{y=0}^{255} p(y) \sum_{c=1}^{C} S_n(\mu_c(y))$$

---

## üìä H√†m Membership

### Tam Gi√°c (Triangular) - Khuy√™n D√πng
```
    Œº_c(y)
        ^
        |     /\
    1.0 |    /  \
        |   /    \
        |  /      \
    0.0 |_/________\____‚Üí y
        L    C    R
```

**C√¥ng th·ª©c:**
- Khi L ‚â§ y ‚â§ C: $\mu_c(y) = \frac{y - L}{C - L}$
- Khi C < y ‚â§ R: $\mu_c(y) = \frac{R - y}{R - C}$
- Ngo√†i: $\mu_c(y) = 0$

### Gaussian
```
    Œº_c(y)
        ^
        |      ___
    1.0 |     /   \
        |    |  C  |
        |   /       \
    0.0 |__/         \__‚Üí y
```

**C√¥ng th·ª©c:**
$$\mu_c(y) = \exp\left(-\frac{1}{2}\left(\frac{y-C}{\sigma}\right)^2\right)$$

V·ªõi œÉ = Œ± √ó (R - L), th∆∞·ªùng Œ± = 0.5

---

## üíª C√†i ƒê·∫∑t (Python)

### Function Signature
```python
def compute_fuzzy_entropy(
    hist: np.ndarray,              # Histogram 256-bin
    thresholds: List[int],         # Ng∆∞·ª°ng ph√¢n ƒëo·∫°n
    membership: str = "triangular", # Lo·∫°i membership
    for_minimization: bool = False, # Tr·∫£ v·ªÅ -H hay H?
    lambda_penalty: float = 1.0,    # Œª
    alpha_area: float = 0.1,        # Œ±
    beta_membership: float = 0.1    # Œ≤
) -> float:
```

### C√°ch G·ªçi
```python
# Cho MFWOA (maximizer)
fe = compute_fuzzy_entropy(hist, thresholds, 
                          membership="triangular",
                          for_minimization=False,
                          lambda_penalty=1.0,
                          alpha_area=0.10,
                          beta_membership=0.10)

# Cho WOA/PSO (minimizer)
fe = compute_fuzzy_entropy(hist, thresholds,
                          membership="triangular", 
                          for_minimization=True,
                          lambda_penalty=1.0,
                          alpha_area=0.10,
                          beta_membership=0.10)
```

---

## üîÑ Quy Tr√¨nh T√≠nh To√°n (12 B∆∞·ªõc)

1. **Ki·ªÉm tra input** ‚Üí hist shape (256,)
2. **Chu·∫©n ho√° histogram** ‚Üí p_levels (x√°c su·∫•t)
3. **R√†ng bu·ªôc ng∆∞·ª°ng** ‚Üí enforce_threshold_constraints()
4. **X√¢y d·ª±ng t√¢m l·ªõp** ‚Üí centers = [0, t1, t2, ..., tk, 255]
5. **Sinh membership** ‚Üí Œº_c(y) = _triangular_membership(centers)
6. **T√≠nh x√°c su·∫•t l·ªõp** ‚Üí p_classes = Œº ¬∑ p_levels
7. **Ki·ªÉm tra l·ªõp r·ªóng** ‚Üí if p_classes < Œµ ‚Üí penalty
8. **T√≠nh Shannon Entropy** ‚Üí S = -Œº¬∑log(Œº) - (1-Œº)¬∑log(1-Œº)
9. **FE t·ªïng th·ªÉ** ‚Üí H = C ¬∑ (1/ln2) ¬∑ Œ£ p(y) ¬∑ Œ£ S_n(Œº)
10. **Penalty di·ªán t√≠ch** ‚Üí P_A = Œ£ (p_c - 1/C)¬≤
11. **Penalty membership** ‚Üí P_Œº = max(Œº)¬≤
12. **√Åp d·ª•ng ph·∫°t** ‚Üí F' = H - Œª[Œ±¬∑P_A + Œ≤¬∑P_Œº]

---

## üìà ·∫¢nh H∆∞·ªüng C·ªßa Tham S·ªë

### TƒÉng Œª (lambda_penalty)
```
Œª = 0.0:  FE cao, threshold x·∫•u (kh√¥ng c√¢n b·∫±ng)
Œª = 0.5:  FE trung b√¨nh, threshold b√¨nh th∆∞·ªùng
Œª = 1.0:  FE v·ª´a ph·∫£i, threshold c√¢n b·∫±ng t·ªët
Œª = 2.0:  FE th·∫•p, threshold r·∫•t c√¢n b·∫±ng nh∆∞ng m·∫•t FE
```

### TƒÉng Œ± (alpha_area)
```
Œ± = 0.0:   L·ªõp kh√¥ng b·ªã ph·∫°t k√≠ch th∆∞·ªõc
Œ± = 0.1:   Nh·∫π: l·ªõp c√≥ th·ªÉ ch√™nh l·ªách 5-10%
Œ± = 0.3:   M·∫°nh: l·ªõp bu·ªôc c√¢n b·∫±ng h∆°n ~2-3%
Œ± = 0.5+:  R·∫•t m·∫°nh: l·ªõp c√¢n b·∫±ng l√Ω t∆∞·ªüng
```

### TƒÉng Œ≤ (beta_membership)
```
Œ≤ = 0.0:   Membership kh√¥ng b·ªã ph·∫°t
Œ≤ = 0.1:   Nh·∫π: membership c√≥ th·ªÉ spike ƒë·∫øn 0.9-1.0
Œ≤ = 0.3:   M·∫°nh: membership gi·ªØ ‚â§ 0.8
Œ≤ = 0.5+:  R·∫•t m·∫°nh: membership m·ªÅm, max ‚â§ 0.7
```

---

## üß™ K·∫øt Qu·∫£ M·∫´u (Lena, K=4)

### V·ªõi Œª=1.0, Œ±=0.1, Œ≤=0.1
```
Thu·∫≠t To√°n | Ng∆∞·ª°ng          | FE     | Th·ªùi Gian
-----------|-----------------|--------|----------
MFWOA      | [155, 170, 197] | 4.658  | 0.15s (t·ªët nh·∫•t)
WOA        | [25, 73, 100]   | 4.451  | 0.15s
PSO        | [24, 75, 78]    | 4.627  | 0.14s
Otsu       | [57, 90, 120]   | 4.332  | 2.39s (baseline)
```

### ƒêi·ªÅu Ch·ªânh Tham S·ªë
```
Œª=0.5  ‚Üí MFWOA FE ‚âà 4.72 (tƒÉng), threshold k√©m c√¢n b·∫±ng
Œª=2.0  ‚Üí MFWOA FE ‚âà 4.60 (gi·∫£m), threshold r·∫•t c√¢n b·∫±ng
```

---

## üéì Tham Kh·∫£o L√Ω Thuy·∫øt

**Fuzzy Entropy:**
- De Luca, A., & Termini, S. (1972). A definition of a nonprobabilistic entropy in the setting of fuzzy sets theory. *Information and Control*, 20(4), 301-312.

**·ª®ng D·ª•ng Ph√¢n ƒêo·∫°n:**
- Gong, M., Zhou, Z., & Luan, J. (2010). Fuzzy c-means clustering with local information and kernel metric for image segmentation. *Neurocomputing*, 73(10-12), 1759-1766.

**MFWOA (Whale Optimization):**
- Mirjalili, S., & Lewis, A. (2016). The whale optimization algorithm. *Advances in Engineering Software*, 95, 51-67.

---

## ‚úÖ Checklist Ki·ªÉm Tra

- [x] C√¥ng th·ª©c De Luca hi·ªán th·ª±c ƒë√∫ng
- [x] Penalty ƒë·ªông t√≠nh to√°n ch√≠nh x√°c
- [x] Objective functions s·ª≠ d·ª•ng c√¥ng th·ª©c m·ªõi
- [x] Ch√∫ th√≠ch code chi ti·∫øt
- [x] T√†i li·ªáu to√°n h·ªçc ƒë·∫ßy ƒë·ªß
- [x] V√≠ d·ª• & k·∫øt qu·∫£ th·ª≠ nghi·ªám
- [x] H∆∞·ªõng d·∫´n tham s·ªë ƒëi·ªÅu ch·ªânh

---

## üìû H·ªèi ƒê√°p Nhanh

**Q: Khi n√†o s·ª≠ d·ª•ng triangular vs gaussian?**
A: Triangular cho t·ªëc ƒë·ªô & ƒë∆°n gi·∫£n; Gaussian cho m·ªÅm m·∫°i & continuous.

**Q: FE cao t·ªët hay x·∫•u?**
A: FE cao = m·ªù h∆°n; k·∫øt h·ª£p v·ªõi PSNR/SSIM/DICE ƒë·ªÉ ƒë√°nh gi√°.

**Q: L√†m sao ƒëi·ªÅu ch·ªânh Œª, Œ±, Œ≤?**
A: B·∫Øt ƒë·∫ßu Œª=1, Œ±=0.1, Œ≤=0.1; tƒÉng Œ± n·∫øu mu·ªën l·ªõp c√¢n b·∫±ng h∆°n.

**Q: Penalty n√†o quan tr·ªçng h∆°n?**
A: Ph·ª• thu·ªôc b√†i to√°n; th∆∞·ªùng P_A (di·ªán t√≠ch) quan tr·ªçng h∆°n.

**Q: for_minimization=True/False l√† g√¨?**
A: True cho WOA/PSO (minimize); False cho MFWOA (maximize).
