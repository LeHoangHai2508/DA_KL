# H∆∞·ªõng D·∫´n Fuzzy Entropy De Luca v·ªõi C√¥ng Th·ª©c Ph·∫°t

## 1. C√¥ng Th·ª©c Fuzzy Entropy De Luca

### 1.1 ƒê·ªãnh Nghƒ©a To√°n H·ªçc

**C√¥ng th·ª©c ch√≠nh:**
$$H = -K \sum_{i=1}^{n} \left[ \rho_i \log(\rho_i) + (1-\rho_i) \log(1-\rho_i) \right]$$

Trong ƒë√≥:
- **H**: Fuzzy Entropy (gi√° tr·ªã entropy m·ªù)
- **K**: H·∫±ng s·ªë chu·∫©n ho√° = $\frac{1}{\ln(2)}$ ‚âà 1.4427
- **n**: S·ªë m·ª©c x√°m trong ·∫£nh (256 cho ·∫£nh 8-bit)
- **œÅ_i** (rho_i): ƒê·ªô th√†nh vi√™n m·ªù (membership) c·ªßa pixel i trong l·ªõp ƒë∆∞·ª£c ch·ªçn
  - œÅ_i ‚àà [0, 1]
  - œÅ_i = 1: ho√†n to√†n thu·ªôc l·ªõp (membership cao)
  - œÅ_i = 0.5: kh√¥ng ch·∫Øc ch·∫Øn (m·ªù t·ªëi ƒëa)
  - œÅ_i = 0: ho√†n to√†n kh√¥ng thu·ªôc l·ªõp

### 1.2 Shannon Entropy Component

Th√†nh ph·∫ßn entropy Shannon cho m·ªói pixel:
$$S_n(\rho) = -\rho \log(\rho) - (1-\rho) \log(1-\rho)$$

**√ù nghƒ©a:**
- Khi œÅ = 0 ho·∫∑c 1: S_n = 0 (kh√¥ng m·ªù, entropy th·∫•p, d·ª± ƒëo√°n ch·∫Øc ch·∫Øn)
- Khi œÅ = 0.5: S_n = log(2) ‚âà 0.693 (m·ªù c·ª±c ƒë·∫°i, entropy cao, kh√¥ng ch·∫Øc ch·∫Øn)

### 1.3 C√¥ng Th·ª©c T√≠nh FE Tr√™n Histogram

Tr√™n histogram 1D:
$$H = C \cdot \frac{1}{\ln(2)} \sum_{y=0}^{255} p(y) \sum_{c=1}^{C} S_n(\mu_c(y))$$

Trong ƒë√≥:
- **C**: S·ªë l·ªõp (= k + 1, v·ªõi k l√† s·ªë ng∆∞·ª°ng)
- **p(y)**: X√°c su·∫•t m·ª©c x√°m y = hist[y] / t·ªïng_pixel
- **Œº_c(y)**: ƒê·ªô th√†nh vi√™n c·ªßa m·ª©c x√°m y trong l·ªõp c
  - Ph·ª• thu·ªôc v√†o h√†m membership (tam gi√°c, Gaussian,...)
  - ƒê∆∞·ª£c t√≠nh t·ª´ v·ªã tr√≠ c√°c ng∆∞·ª°ng

---

## 2. C√¥ng Th·ª©c Ph·∫°t (Penalty Function)

### 2.1 C√¥ng Th·ª©c T·ªïng Qu√°t

**Fuzzy Entropy v·ªõi ph·∫°t:**
$$F'(T) = F(T) - \lambda[\alpha P_A(T) + \beta P_\mu(T)]$$

Trong ƒë√≥:
- **F'(T)**: Fuzzy Entropy ƒë√£ ƒëi·ªÅu ch·ªânh (c√≥ ph·∫°t)
- **F(T)**: Fuzzy Entropy g·ªëc (kh√¥ng ph·∫°t)
- **Œª** (lambda): H·ªá s·ªë c√¢n n·∫∑ng chung (0 ‚â§ Œª ‚â§ 1, th∆∞·ªùng Œª=1.0)
- **Œ±**: H·ªá s·ªë cho penalty di·ªán t√≠ch (th∆∞·ªùng Œ±=0.1)
- **Œ≤**: H·ªá s·ªë cho penalty membership (th∆∞·ªùng Œ≤=0.1)
- **P_A(T)**: Penalty di·ªán t√≠ch (ph·∫°t l·ªõp kh√¥ng c√¢n b·∫±ng)
- **P_Œº(T)**: Penalty membership (ph·∫°t membership qu√° t·∫≠p trung)

### 2.2 Penalty Di·ªán T√≠ch - P_A(T)

**M·ª•c ƒë√≠ch:** Khuy·∫øn kh√≠ch c√°c l·ªõp c√≥ k√≠ch th∆∞·ªõc c√¢n b·∫±ng

**C√¥ng th·ª©c:**
$$P_A(T) = \sum_{c=1}^{C} \left( p_c - \frac{1}{C} \right)^2$$

Trong ƒë√≥:
- **p_c**: X√°c su·∫•t (k√≠ch th∆∞·ªõc t∆∞∆°ng ƒë·ªëi) c·ªßa l·ªõp c
  - $p_c = \sum_{y=0}^{255} \mu_c(y) \cdot p(y)$
- **1/C**: X√°c su·∫•t trung b√¨nh l√Ω t∆∞·ªüng (m·ªói l·ªõp = 1/C)

**√ù nghƒ©a:**
- P_A = 0: T·∫•t c·∫£ l·ªõp c√≥ k√≠ch th∆∞·ªõc b·∫±ng nhau (l√Ω t∆∞·ªüng)
- P_A > 0: C√≥ l·ªõp ch√™nh l·ªách v·ªÅ k√≠ch th∆∞·ªõc (c·∫ßn ph·∫°t)

**V√≠ d·ª•:** 
- N·∫øu K=4, l√Ω t∆∞·ªüng m·ªói l·ªõp c√≥ 25% pixel
- N·∫øu l·ªõp 1 c√≥ 40%, l·ªõp 2 c√≥ 5% ‚Üí P_A l·ªõn ‚Üí b·ªã ph·∫°t

### 2.3 Penalty Membership - P_Œº(T)

**M·ª•c ƒë√≠ch:** Ph·∫°t khi membership qu√° t·∫≠p trung (spike)

**C√¥ng th·ª©c:**
$$P_\mu(T) = \max_{c,y} (\mu_c(y))^2$$

Ho·∫∑c c√≥ th·ªÉ l√†:
$$P_\mu(T) = -\sum_{c=1}^{C} p_c \log(p_c) \quad \text{(entropy th·∫•p)}$$

**√ù nghƒ©a:**
- Ph·∫°t n·∫øu membership ·ªü m·ªôt pixel qu√° cao (d·∫´n ƒë·∫øn overfitting)
- Khuy·∫øn kh√≠ch membership m·ªÅm, ph√¢n t√°n

---

## 3. C√†i ƒê·∫∑t Trong Code

### 3.1 H√†m compute_fuzzy_entropy

```python
def compute_fuzzy_entropy(
    hist: np.ndarray,
    thresholds: Sequence[int],
    membership: MembershipType = "triangular",
    for_minimization: bool = False,
    lambda_penalty: float = 1.0,      # H·ªá s·ªë Œª
    alpha_area: float = 0.1,          # H·ªá s·ªë Œ±
    beta_membership: float = 0.1,     # H·ªá s·ªë Œ≤
) -> float:
```

**C√°c b∆∞·ªõc t√≠nh to√°n:**

1. **Chu·∫©n ho√° histogram ‚Üí ph√¢n ph·ªëi x√°c su·∫•t**
   ```python
   p_levels = hist / sum(hist)  # p(y) cho y=0..255
   ```

2. **T·∫°o ma tr·∫≠n membership Œº_c(y)**
   ```python
   mu = _triangular_membership(centers)  # shape (C, 256)
   # Œº_c(y) = ƒë·ªô th√†nh vi√™n c·ªßa m·ª©c x√°m y trong l·ªõp c
   ```

3. **T√≠nh x√°c su·∫•t m·ªói l·ªõp**
   ```python
   p_classes = mu.dot(p_levels)  # p_c = Œ£_y Œº_c(y) * p(y)
   ```

4. **Ki·ªÉm tra l·ªõp r·ªóng**
   ```python
   if any(p_classes < Œµ):  # L·ªõp r·ªóng -> ph·∫°t n·∫∑ng
       return FITNESS_PENALTY
   ```

5. **T√≠nh Shannon Entropy cho t·ª´ng pixel-l·ªõp**
   ```python
   S = -Œº * log(Œº) - (1-Œº) * log(1-Œº)  # shape (C, 256)
   ```

6. **T√≠nh Fuzzy Entropy t·ªïng th·ªÉ**
   ```python
   H = C * (1/ln(2)) * Œ£_y p(y) * Œ£_c S_n(Œº_c(y))
   ```

7. **T√≠nh Penalty Di·ªán T√≠ch**
   ```python
   mean_prob = 1.0 / C
   P_A = Œ£_c (p_c - mean_prob)¬≤
   ```

8. **T√≠nh Penalty Membership**
   ```python
   P_Œº = max(Œº)¬≤  # Gi√° tr·ªã membership l·ªõn nh·∫•t
   ```

9. **√Åp d·ª•ng c√¥ng th·ª©c ph·∫°t**
   ```python
   F'(T) = F(T) - Œª[Œ±¬∑P_A + Œ≤¬∑P_Œº]
   ```

10. **Tr·∫£ v·ªÅ k·∫øt qu·∫£**
    ```python
    return -F' n·∫øu for_minimization else F'
    ```

### 3.2 C√°c Tham S·ªë ƒê·ªÅ Xu·∫•t

| Tham s·ªë | Gi√° Tr·ªã | M√¥ T·∫£ |
|--------|---------|-------|
| Œª (lambda_penalty) | 1.0 | H·ªá s·ªë c√¢n n·∫∑ng chung (d√πng 1.0 cho ·∫£nh c√¢n b·∫±ng) |
| Œ± (alpha_area) | 0.1 | Penalty di·ªán t√≠ch (0.05-0.20) |
| Œ≤ (beta_membership) | 0.1 | Penalty membership (0.05-0.20) |

**H∆∞·ªõng d·∫´n ƒëi·ªÅu ch·ªânh:**
- **TƒÉng Œª**: Ph·∫°t m·∫°nh h∆°n ‚Üí thresholds c√¢n b·∫±ng h∆°n nh∆∞ng c√≥ th·ªÉ m·∫•t FE cao
- **TƒÉng Œ±**: Ph·∫°t l·ªõp kh√¥ng c√¢n b·∫±ng ‚Üí l·ªõp c√≥ k√≠ch th∆∞·ªõc ƒë·ªìng ƒë·ªÅu
- **TƒÉng Œ≤**: Ph·∫°t membership spike ‚Üí membership m·ªÅm h∆°n

---

## 4. H√†m Membership

### 4.1 Tam Gi√°c (Triangular)

```
Œº_c(y)
  ^
  |     /\
1 |    /  \
  |   /    \
  |  /      \
0 |_/________\____‚Üí y
  left  c  right
```

**C√¥ng th·ª©c:**
- T·ª´ left ‚Üí c: Œº = (y - left) / (c - left)
- T·ª´ c ‚Üí right: Œº = (right - y) / (right - c)
- Ngo√†i [left, right]: Œº = 0

**∆Øu ƒëi·ªÉm:**
- ƒê∆°n gi·∫£n, nhanh, d·ªÖ hi·ªÉu
- Th∆∞·ªùng d√πng cho ·ª©ng d·ª•ng th·ª±c t·∫ø

### 4.2 Gaussian

```
Œº_c(y)
  ^
  |      ___
1 |     /   \
  |    |  c  |
  |   /       \
0 |__/         \__‚Üí y
  left      right
```

**C√¥ng th·ª©c:**
$$\mu_c(y) = \exp\left(-\frac{1}{2}\left(\frac{y-c}{\sigma}\right)^2\right)$$

V·ªõi œÉ = Œ± √ó (right - left)

**∆Øu ƒëi·ªÉm:**
- M·ªÅm m·∫°i, smooth
- Membership t·∫°i bi√™n kh√¥ng b·∫±ng 0 (chuy·ªÉn ti·∫øp √™m)

---

## 5. V√≠ D·ª• C·ª• Th·ªÉ

### 5.1 T√≠nh FE cho Lena (K=4 threshold)

**Input:**
- ·∫¢nh: Lena (512√ó512 grayscale)
- Ng∆∞·ª°ng: [57, 90, 120, 155]
- Membership: tam gi√°c
- C√¥ng th·ª©c: De Luca v·ªõi Œª=1, Œ±=0.1, Œ≤=0.1

**Output:**
```
Otsu:   FE ‚âà 4.332
MFWOA:  FE ‚âà 4.658
WOA:    FE ‚âà 4.451
PSO:    FE ‚âà 4.627
```

**Gi·∫£i th√≠ch:**
- MFWOA ƒë·∫°t FE cao nh·∫•t v√¨ s·ª≠ d·ª•ng t·ªëi ∆∞u ho√° (kh√¥ng b·ªã gi·ªõi h·∫°n nh∆∞ Otsu)
- C√¥ng th·ª©c ph·∫°t l√†m cho ng∆∞·ª°ng c√¢n b·∫±ng, kh√¥ng t·∫≠p trung v√†o m·ªôt ph·∫ßn

### 5.2 T√°c ƒê·ªông C·ªßa Penalty

**Kh√¥ng ph·∫°t (Œª=0):**
- FE c√≥ th·ªÉ cao h∆°n
- Nh∆∞ng threshold c√≥ th·ªÉ kh√¥ng c√¢n b·∫±ng (v√≠ d·ª•: t·∫≠p trung ·ªü m·ªôt ph·∫ßn)

**V·ªõi ph·∫°t (Œª=1):**
- FE th·∫•p h∆°n m·ªôt ch√∫t
- Nh∆∞ng threshold c√¢n b·∫±ng, c√°c l·ªõp c√≥ k√≠ch th∆∞·ªõc ƒë·ªìng ƒë·ªÅu

---

## 6. C√°c C√¥ng Th·ª©c S·ª≠ D·ª•ng Trong Th·ª±c Nghi·ªám

### 6.1 PSNR (Peak Signal-to-Noise Ratio)

$$\text{PSNR} = 10 \log_{10} \left( \frac{L^2}{MSE} \right)$$

- L = 255 (max value)
- MSE = mean squared error gi·ªØa ·∫£nh g·ªëc v√† ·∫£nh ph√¢n ƒëo·∫°n ƒë∆∞·ª£c t√°i c·∫•u tr√∫c

### 6.2 SSIM (Structural Similarity Index)

$$\text{SSIM}(x,y) = \frac{(2\mu_x\mu_y + c_1)(2\sigma_{xy} + c_2)}{(\mu_x^2 + \mu_y^2 + c_1)(\sigma_x^2 + \sigma_y^2 + c_2)}$$

- ƒêo ƒë·ªô t∆∞∆°ng t·ª± c·∫•u tr√∫c gi·ªØa hai ·∫£nh
- SSIM ‚àà [-1, 1], cao h∆°n = t·ªët h∆°n

### 6.3 DICE (Dice Similarity Coefficient)

$$\text{DICE} = \frac{2|X \cap Y|}{|X| + |Y|}$$

- X: t·∫≠p h·ª£p pixel foreground trong segmentation
- Y: t·∫≠p h·ª£p pixel foreground trong ground truth
- DICE ‚àà [0, 1], cao h∆°n = t·ªët h∆°n

---

## 7. T√≥m T·∫Øt & L·ªùi Khuy·∫øn C√°o

**Fuzzy Entropy De Luca:**
- ‚úÖ T√≠nh to√°n m·ª©c ƒë·ªô m·ªù (uncertainty) c·ªßa ph√¢n ƒëo·∫°n
- ‚úÖ C√≥ th·ªÉ ƒëi·ªÅu ch·ªânh qua h√†m membership
- ‚úÖ K·∫øt h·ª£p penalty ƒë·ªÉ c√¢n b·∫±ng thresholds

**Khi s·ª≠ d·ª•ng:**
- üìå FE cao ‚â† ph√¢n ƒëo·∫°n t·ªët (c·∫ßn c√¢n b·∫±ng FE + PSNR/SSIM/DICE)
- üìå Penalty gi√∫p tr√°nh threshold "x·∫•u" (kh√¥ng c√¢n b·∫±ng)
- üìå ƒêi·ªÅu ch·ªânh Œª, Œ±, Œ≤ tu·ª≥ theo b√†i to√°n c·ª• th·ªÉ

**Tham kh·∫£o:** 
- De Luca, A., & Termini, S. (1972). A definition of a nonprobabilistic entropy in the setting of fuzzy sets theory.
- Gong, M., Zhou, Z., & Luan, J. (2010). Fuzzy c-means clustering with local information and kernel metric for image segmentation.
